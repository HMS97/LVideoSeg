{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path import Path\n",
    "len(Path('/mnt/drive1/hsun/video_datasets/CondensedMovies/videos/2019').files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt-dlp --config-location /mnt/drive1/hsun/CondensedMovies/data_prep/youtube-dl.conf -P /mnt/drive1/hsun/video_datasets/CondensedMovies/videos/2012 -a  /mnt/drive1/hsun/CondensedMovies/data/metadata/youtube-dl-dump/2012.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3692552401.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    yt-dlp --config-location /mnt/drive1/hsun/CondensedMovies/data_prep/youtube-dl.conf -P /mnt/drive1/hsun/video_datasets/CondensedMovies/videos/2014 -a  /mnt/drive1/hsun/CondensedMovies/data/metadata/youtube-dl-dump/2014.csv\u001b[0m\n\u001b[0m                                                                                                                                                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "yt-dlp --config-location /mnt/drive1/hsun/CondensedMovies/data_prep/youtube-dl.conf -P /mnt/drive1/hsun/video_datasets/CondensedMovies/videos/2020 -a  /mnt/drive1/hsun/CondensedMovies/data/metadata/youtube-dl-dump/2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from path import Path\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # get the frames per second of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # frame index\n",
    "    idx = 0\n",
    "    folder_path = '/mnt/drive1/brick1/hsun/videoSeg/data/test_folder'\n",
    "    # output directory for each video\n",
    "    out_dir = os.path.join(folder_path, video_path.stem)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # save every fps-th frame\n",
    "        if idx % int(fps) == 0:\n",
    "            cv2.imwrite(os.path.join(out_dir, f'frame_{int(idx / fps)}.png'), frame)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    \n",
    "process_video(Path('/mnt/drive1/brick1/hsun/videoSeg/data/my-video.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29901/29901 [18:01<00:00, 27.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the list of all videos\n",
    "# video_paths = list(Path('dataset/mp4_video').files(\"*.mp4\"))\n",
    "# video_paths = [  i  for i in Path('/mnt/drive1/hsun/video_datasets/CondensedMovies/videos').dirs()]\n",
    "sub_lists = [  i.files()  for i in Path('/mnt/drive1/hsun/video_datasets/CondensedMovies/videos').dirs()]\n",
    "\n",
    "video_paths =  [item for sublist in sub_lists for item in sublist]\n",
    "# Create a multiprocessing Pool\n",
    "pool = Pool(processes = 100)\n",
    "\n",
    "# Process the videos in parallel\n",
    "for _ in tqdm(pool.imap_unordered(process_video, video_paths), total=len(video_paths)):\n",
    "    pass\n",
    "\n",
    "# Close the pool\n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268872"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Path('videos_frames').dirs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (891577297.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 56\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('dump json to ', os.path.join(target_folder, str(longvideo_count), 'video_folders length: ', video_folders)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "def extend_frame_count(subfolder, min_video_length):\n",
    "    \"\"\"If a subfolder has fewer than min_video_length frames, append frames from the beginning.\"\"\"\n",
    "    frames = deque(sorted(os.listdir(subfolder)))\n",
    "    extended_frames = list(frames)  # copy original frame order\n",
    "\n",
    "    if len(frames)< min_video_length:\n",
    "        while len(extended_frames) < min_video_length:\n",
    "            extended_frames.extend(frames)\n",
    "\n",
    "        return extended_frames\n",
    "    else:\n",
    "        return frames\n",
    "\n",
    "def combine_frames(source_folder, target_folder, min_video_count, max_video_count,minimum_video_length = 10):\n",
    "    \"\"\"Combine frames from subfolders in source_folder into target_folder, ensuring each subfolder\n",
    "    has at least min_video_length frames.\"\"\"\n",
    "    video_folders = deque(os.listdir(source_folder))\n",
    "    total_length = video_folders\n",
    "    print('video_folders length', len(video_folders))\n",
    "    json_data = {}\n",
    "    video_start_points = []\n",
    "    frame_start_point = 0\n",
    "    longvideo_count = 0\n",
    "    \n",
    "    while video_folders:\n",
    "        longvideo_count += 1\n",
    "        random_video_count = random.randint(min_video_count, max_video_count)  # Generate a random number of videos\n",
    "        os.makedirs(os.path.join(target_folder, str(longvideo_count)), exist_ok=True)\n",
    "        json_data = {}\n",
    "        video_start_points = []\n",
    "        frame_start_point = 0\n",
    "\n",
    "        while video_folders and random_video_count > 0:\n",
    "            subfolder = video_folders.popleft()\n",
    "            subfolder_path = os.path.join(source_folder, subfolder)\n",
    "\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                extended_frames = extend_frame_count(subfolder_path, minimum_video_length)\n",
    "                video_length = len(extended_frames)\n",
    "                video_start_points.append(frame_start_point)  # Store start point of each new video\n",
    "\n",
    "                for index, frame in enumerate(extended_frames):\n",
    "                    # Rename the frame to be sequential in the new folder\n",
    "                    new_frame_name = f\"frame_{frame_start_point + index}.jpg\"\n",
    "                    shutil.copy(os.path.join(subfolder_path, frame), os.path.join(target_folder, str(longvideo_count), new_frame_name))\n",
    "\n",
    "                json_data[subfolder] = {\"start_frame\": frame_start_point, \"end_frame\": frame_start_point + video_length - 1}\n",
    "                frame_start_point += video_length\n",
    "                random_video_count -= 1\n",
    "\n",
    "        print( 'left video length: ', video_folders)\n",
    "\n",
    "        # Create a JSON file\n",
    "        with open(os.path.join(target_folder, str(longvideo_count), 'frame_data.json'), 'w') as json_file:\n",
    "            json.dump({\"video_data\": json_data, \"video_start_points\": video_start_points[1:]}, json_file)\n",
    "        \n",
    "# Define your source and target folder here:\n",
    "source_folder = '/mnt/drive1/hsun/videos_frames'\n",
    "target_folder = '/mnt/drive1/hsun/new_videos'\n",
    "min_video_count = 2  # The minimum number of videos to consider\n",
    "max_video_count = 80  # The maximum number of videos to consider\n",
    "minimum_video_length = 10\n",
    "# Ensure the target folder exists\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "combine_frames(source_folder, target_folder, min_video_count, max_video_count,  minimum_video_length = minimum_video_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path import Path\n",
    "\n",
    "len(Path('/mnt/drive1/hsun/new_videos').dirs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "\n",
    "import shutil \n",
    "\n",
    "import os\n",
    "\n",
    "files = [i.files() for i in Path('/mnt/drive1/hsun/videoSeg/data/video_datasets/CondensedMovies/video_frames').dirs()]\n",
    "\n",
    "for i in files:\n",
    "    sorted_i = sorted(i, key=lambda x: int(x.stem.split('_')[-1]))\n",
    "    for j in sorted_i[-20:]:\n",
    "        os.remove(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29901"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( Path('/mnt/drive1/hsun/video_datasets/CondensedMovies/video_frames').dirs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
